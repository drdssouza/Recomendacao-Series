{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPDe9o+YvIb1ZAi2gHyArvg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/drdssouza/Recomendacao-Series/blob/main/RecomendacaoSeries.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Código fazendo a limpeza dos dados na API do TMDB para séries de Crime, Guerra e Mistério"
      ],
      "metadata": {
        "id": "9m4M5RyPqP2_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importando as bibliotecas necessárias"
      ],
      "metadata": {
        "id": "WNd3zDWqm3yx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "H__ylavYmsp8"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import json\n",
        "import math"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definição das funções"
      ],
      "metadata": {
        "id": "srWAkEe8m9eH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def obter_resposta_api(url):\n",
        "    resposta = requests.get(url)\n",
        "    return resposta.json()\n",
        "\n",
        "def obter_mapa_id_para_nome_genero(api_key):\n",
        "    url_generos = f'https://api.themoviedb.org/3/genre/tv/list?api_key={api_key}&language=pt-BR'\n",
        "    dados_generos = obter_resposta_api(url_generos)\n",
        "\n",
        "    mapa_id_para_nome = {}\n",
        "\n",
        "    for genero in dados_generos['genres']:\n",
        "        mapa_id_para_nome[genero['id']] = genero['name']\n",
        "\n",
        "    return mapa_id_para_nome\n",
        "\n",
        "def obter_detalhes_serie(api_key, id_serie):\n",
        "    url_detalhes_serie = f'https://api.themoviedb.org/3/tv/{id_serie}?api_key={api_key}&language=pt-BR'\n",
        "    return obter_resposta_api(url_detalhes_serie)\n",
        "\n",
        "def filtrar_series(api_key, todos_resultados, generos_desejados):\n",
        "    mapa_id_para_nome = obter_mapa_id_para_nome_genero(api_key)\n",
        "    series_filtradas = []\n",
        "\n",
        "    for serie in todos_resultados:\n",
        "        ids_generos = serie['genre_ids']\n",
        "\n",
        "        if any(id_genero in generos_desejados for id_genero in ids_generos):\n",
        "            nomes_generos_desejados_str = ','.join(mapa_id_para_nome[id_genero] for id_genero in ids_generos if id_genero in generos_desejados)\n",
        "\n",
        "            id_serie = str(serie['id'])\n",
        "            detalhes_serie = obter_detalhes_serie(api_key, id_serie)\n",
        "\n",
        "            empresas_producao = [empresa['name'] for empresa in detalhes_serie.get('production_companies', [])]\n",
        "            empresas_producao_str = ', '.join(empresas_producao)\n",
        "\n",
        "            paises_producao_str = ', '.join(detalhes_serie.get('origin_country', []))\n",
        "\n",
        "            numero_temporadas = detalhes_serie.get('number_of_seasons', '')\n",
        "            numero_episodios = detalhes_serie.get('number_of_episodes', '')\n",
        "            media_votos = detalhes_serie.get('vote_average', '')\n",
        "\n",
        "            if paises_producao_str and empresas_producao_str:\n",
        "                series_filtradas.append({\n",
        "                    'id': id_serie,\n",
        "                    'nome_original': serie['original_name'],\n",
        "                    'generos': nomes_generos_desejados_str,\n",
        "                    'data_estreia': serie['first_air_date'],\n",
        "                    'popularidade': serie['popularity'],\n",
        "                    'empresas_producao': empresas_producao_str,\n",
        "                    'paises_producao': paises_producao_str,\n",
        "                    'numero_temporadas': numero_temporadas,\n",
        "                    'numero_episodios': numero_episodios,\n",
        "                    'media_votos': media_votos\n",
        "                })\n",
        "\n",
        "    return series_filtradas\n",
        "\n",
        "def salvar_lote_series(lote_series, indice_lote):\n",
        "    nome_arquivo = f'series_filtradas_{indice_lote + 1}.json'\n",
        "    conteudo_arquivo = json.dumps(lote_series)\n",
        "\n",
        "    with open(nome_arquivo, 'w') as f:\n",
        "        f.write(conteudo_arquivo)\n"
      ],
      "metadata": {
        "id": "Ygx_4KZ7nBA7"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definindo a função MAIN\n",
        "- Coloque sua API no campo api_key\n",
        "- Definda a quantidade de páginas a fazer a busca no campo total_paginas\n"
      ],
      "metadata": {
        "id": "PNpPFCqrnIXr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    api_key = 'df17b17c4e452ad1676517f6fa195825'\n",
        "    url = f'https://api.themoviedb.org/3/tv/popular?language=pt-BR&page=1&api_key={api_key}'\n",
        "\n",
        "    resposta = obter_resposta_api(url)\n",
        "    todos_resultados = resposta['results']\n",
        "\n",
        "    pagina = 1\n",
        "    total_paginas = 500\n",
        "\n",
        "    while pagina < total_paginas:\n",
        "        pagina += 1\n",
        "        url_atualizada = url.replace('page=1', f'page={pagina}')\n",
        "        resposta = obter_resposta_api(url_atualizada)\n",
        "        todos_resultados.extend(resposta['results'])\n",
        "\n",
        "    generos_desejados = [80, 10752, 9648]  # IDs dos gêneros Crime, Guerra e Mistério\n",
        "\n",
        "    series_filtradas = filtrar_series(api_key, todos_resultados, generos_desejados)\n",
        "\n",
        "    tamanho_lote = 100\n",
        "    total_lotes = math.ceil(len(series_filtradas) / tamanho_lote)\n",
        "\n",
        "    for indice_lote in range(total_lotes):\n",
        "        inicio_lote = indice_lote * tamanho_lote\n",
        "        fim_lote = inicio_lote + tamanho_lote\n",
        "        lote_series = series_filtradas[inicio_lote:fim_lote]\n",
        "        salvar_lote_series(lote_series, indice_lote)"
      ],
      "metadata": {
        "id": "wxCPxvs_nP2Z"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Com a API e o total de páginas definidas ali em cima, rode o código abaixo:"
      ],
      "metadata": {
        "id": "-LUFMKrfnS4N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "id": "TLOk-KQfnW0c"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sistema de Recomendação de série com Machine Learning"
      ],
      "metadata": {
        "id": "Tv3yFshQqbUZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importação das bibliotecas"
      ],
      "metadata": {
        "id": "TDLMKhtAqh3p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.utils import simple_preprocess"
      ],
      "metadata": {
        "id": "tFo-tcmtqkKb"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definindo as Funções"
      ],
      "metadata": {
        "id": "G0_ykPvnqwG1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def carregar_series_from_json():\n",
        "    series = []\n",
        "    for i in range(15):\n",
        "        filename = f'series_filtradas_{i + 1}.json'\n",
        "        with open(filename, 'r') as f:\n",
        "            series_data = json.load(f)\n",
        "            series.extend(series_data)\n",
        "    return series\n",
        "\n",
        "def preprocessar_dados(series):\n",
        "    df_series = pd.DataFrame(series)\n",
        "    if 'nome_original' in df_series.columns:\n",
        "        df_series['nome_preprocessado'] = df_series['nome_original'].apply(lambda x: simple_preprocess(x))\n",
        "    return df_series\n",
        "\n",
        "def treinar_modelo(series):\n",
        "    nome_preprocessado = series['nome_preprocessado']\n",
        "    model = Word2Vec(nome_preprocessado, vector_size=100, window=5, min_count=1, workers=4)\n",
        "    return model\n",
        "\n",
        "def recomendar_serie(nome_serie, df_series, model, n=5):\n",
        "    nome_preprocessado = simple_preprocess(nome_serie)\n",
        "    nome_embedding = sum(model.wv[palavra] for palavra in nome_preprocessado if palavra in model.wv) / len(nome_preprocessado)\n",
        "\n",
        "    embeddings = model.wv.vectors\n",
        "    similaridades = cosine_similarity([nome_embedding], embeddings)\n",
        "    indices_similares = similaridades.argsort()[0][::-1][:n]\n",
        "\n",
        "    # Verificar se os índices estão dentro dos limites do conjunto de dados\n",
        "    indices_validos = [idx for idx in indices_similares if idx < len(df_series)]\n",
        "\n",
        "    recomendacoes = df_series.iloc[indices_validos]\n",
        "    return recomendacoes[['nome_original', 'generos', 'popularidade']]\n",
        "\n",
        "def salvar_recomendacoes(recomendacoes):\n",
        "    for i, recomendacao in enumerate(recomendacoes):\n",
        "        nome_arquivo = f'recomendacao_{i+1}.txt'\n",
        "        with open(nome_arquivo, 'w') as f:\n",
        "            f.write(recomendacao.to_string(index=False))\n",
        "\n",
        "def main():\n",
        "    series = carregar_series_from_json()\n",
        "    df_series = preprocessar_dados(series)\n",
        "    if df_series.empty:\n",
        "        print(\"Erro: Não foi possível carregar os dados das séries.\")\n",
        "        return\n",
        "    model = treinar_modelo(df_series)\n",
        "\n",
        "    recomendacoes_total = []\n",
        "\n",
        "    while True:\n",
        "        nome_serie_usuario = input(\"Digite o nome de uma série que você gosta: \")\n",
        "        recomendacoes = recomendar_serie(nome_serie_usuario, df_series, model)\n",
        "\n",
        "        if recomendacoes.empty:\n",
        "            print(\"Não foram encontradas recomendações para a série fornecida.\")\n",
        "            continue\n",
        "\n",
        "        print(recomendacoes)\n",
        "        recomendacoes_total.append(recomendacoes)\n",
        "\n",
        "        continuar = input(\"\\nDeseja continuar? (S para SIM, qualquer tecla para sair): \")\n",
        "        if continuar.lower() != 's':\n",
        "            break\n",
        "\n",
        "    salvar = input(\"\\nDeseja salvar as recomendações em arquivos .txt? (S para SIM, qualquer tecla para continuar): \")\n",
        "    if salvar.lower() == 's':\n",
        "        salvar_recomendacoes(recomendacoes_total)\n",
        "\n",
        "    print(\" =\"*50,\"\\nObrigado por utilizar meu código!\\nRealizado apenas para fins educativos e estudos adicionais sobre Machine Learning.\\n\",\"Feito durante o programa de bolsas da Compassuol\\n\", \" =\"*50,\"\\nCriado por Eduardo Schrotke.\")\n"
      ],
      "metadata": {
        "id": "HROgvH74qyhR"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Executando o código"
      ],
      "metadata": {
        "id": "NAcmqc81q0dR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "id": "lcd6TItlqz3u",
        "outputId": "d40f2a71-9c98-418c-c35a-1d1eabe4c11e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Digite o nome de uma série que você gosta: Desesperate Housewives\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-c7bc734e5e35>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-9-e9684a30e047>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mnome_serie_usuario\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Digite o nome de uma série que você gosta: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mrecomendacoes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecomendar_serie\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnome_serie_usuario\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_series\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecomendacoes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-e9684a30e047>\u001b[0m in \u001b[0;36mrecomendar_serie\u001b[0;34m(nome_serie, df_series, model, n)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0msimilaridades\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnome_embedding\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mindices_similares\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimilaridades\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mcosine_similarity\u001b[0;34m(X, Y, dense_output)\u001b[0m\n\u001b[1;32m   1391\u001b[0m     \u001b[0;31m# to avoid recursive import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1393\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_pairwise_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1395\u001b[0m     \u001b[0mX_normalized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mcheck_pairwise_arrays\u001b[0;34m(X, Y, precomputed, dtype, accept_sparse, force_all_finite, copy)\u001b[0m\n\u001b[1;32m    153\u001b[0m         )\n\u001b[1;32m    154\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         X = check_array(\n\u001b[0m\u001b[1;32m    156\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    900\u001b[0m             \u001b[0;31m# If input is 1D raise error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 902\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m    903\u001b[0m                     \u001b[0;34m\"Expected 2D array, got 1D array instead:\\narray={}.\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[0.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
          ]
        }
      ]
    }
  ]
}